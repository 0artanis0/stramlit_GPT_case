# -*- ecoding: utf-8 -*-
# @ModuleName: app
# @Author: wk
# @Email: 306178200@qq.com
# @Time: 2024/1/28 15:09
import streamlit as st
from chat_model import ChatModel
from knowledge_db import EmbModel, VectorDB
from pdf_processor import extract_text_by_paragraph
from utils import save_uploaded_file
import os

st.title("ç‹é—¨æ™ºèƒ½é—®ç­”å°åŠ©æ‰‹-å†…æµ‹ç‰ˆ")

# å¯¹è¯sessionåˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant",
                                     "content": "ä½ å¥½å•ŠğŸ‘‹æˆ‘æ˜¯ä½ çš„æ™ºèƒ½é—®ç­”å°åŠ©æ‰‹ï¼Œæˆ‘ä¼šæ ¹æ®æ‚¨ä¸Šä¼ çš„æ–‡æ¡£æ¥å›ç­”æ‚¨çš„é—®é¢˜ï¼Œå¸Œæœ›å¯ä»¥å¸®åŠ©æ‚¨"}]
# chatç»„ä»¶è®¾ç½®
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# ä¾§è¾¹æ 
with st.sidebar:
    # Embedding modelé€‰æ‹©
    embedding_model = st.selectbox(
        "Select Embedding Model",
        ['text-embedding-ada-002', 'text-embedding-3-small', 'text-embedding-3-large'],
    )
    # chat modelé€‰æ‹©
    chat_model = st.selectbox(
        "Select Chat Model",
        ['gpt-3.5-turbo-16k', "gpt-3.5-turbo", 'gpt-3.5-turbo-1106', "gpt-4", 'gpt-4-0125-preview',
         'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4o-2024-08-06 '],
    )
    # openai_keyè®¾ç½®
    apikey = st.text_input("è¾“å…¥ä½ çš„OpenAI APIå¯†é’¥", type="password")
    apikey = 'sk-NqzRPn167jVENtffBIWrZwXZ7ALXu347511FkEDVtrDJuXDR'

    # æ–‡ä»¶ä¸Šä¼ å™¨
    uploaded_file = st.file_uploader("Choose a PDF file", type="pdf")

    # å¤„ç†ä¸Šä¼ çš„PDFçŸ¥è¯†åº“
    if uploaded_file is not None:
        # ä¿å­˜æ–‡ä»¶
        saved_file = save_uploaded_file(uploaded_file)
        if saved_file:
            # æå–PDFæ–‡ä»¶å†…å®¹ï¼Œç›®å‰åªæ”¯æŒPDFæ–‡ä»¶
            paragraphs = extract_text_by_paragraph(saved_file)
            if paragraphs:
                # æŠ½å–Embedding
                emb_model = EmbModel({'model_type': 'openai', 'key': apikey})
                text_emb = emb_model.get_all_text_emb(paragraphs)
                emb_model.save_emb(paragraphs, text_emb, './db/temp.json')
                st.success("Embeddings extracted successfullyï¼")
            else:
                st.write("No text extracted from the PDF.")
            # åˆ é™¤ä¸´æ—¶ä¿å­˜çš„æ–‡ä»¶
            if os.path.exists(saved_file):
                os.remove(saved_file)
    else:
        st.stop()

emb_model = EmbModel({'model_type': 'openai', 'key': apikey})
vector_db = VectorDB(emb_model)
vector_db.load_emb('./db/temp.json')
model = ChatModel({'openai-key': apikey, 'model': chat_model, 'model_type': 'openai'}, vector_db)

if prompt := st.chat_input():
    # å¯¹äºuserä¾§ï¼Œå…ˆæŠŠç”¨æˆ·è¾“å…¥å†…å®¹å†™åˆ°sessioné‡Œé¢ï¼Œç„¶åå†™åˆ°å¯¹è¯æ¡†é‡Œé¢
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    # è°ƒç”¨modelè·å–å¤§æ¨¡å‹ç­”å¤
    response = model.ask(prompt)
    # å¯¹å¤§æ¨¡å‹ä¾§ï¼Œå…ˆæŠŠæ¨¡å‹è¾“å‡ºå†…å®¹å†™åˆ°sessioné‡Œé¢ï¼Œç„¶åå†™åˆ°å¯¹è¯æ¡†é‡Œé¢
    st.session_state.messages.append({'role': 'assistant', 'content': response['response']})
    st.chat_message("assistant").write(response['response'])
